---
title: "Ploeg"
author: "G.R. van der Ploeg"
date: "2024-03-12"
output: html_document
---

```{r setup}
library(parafac4microbiome)
library(tidyverse)
library(multiway)
library(ggpubr)
library(cluster)
library(factoextra)
library(ggrepel)
library(scales)
set.seed(123)
```

```{r prep plot data}
# Plot settings
colourCols = c("RFgroup", "Phylum", "")
legendTitles = c("RF group", "Phylum", "")
xLabels = c("Subject index", "Feature index", "Time index")
legendColNums = c(3,5,0)
arrangeModes = c(TRUE, TRUE, FALSE)
continuousModes = c(FALSE,FALSE,TRUE)
```

```{r check sparsity}
sparsity = calculateSparsity(vanderPloeg2024, considerGroups = TRUE, groupVariable = "RFgroup") * 100

a=sparsity[1,] %>% as_tibble() %>% ggplot(aes(x=value)) + geom_histogram(col="black", bins=25) + geom_vline(xintercept=50, col="red", linewidth=1) + xlab("Sparsity (%)") + ylab("Count") + ggtitle("Low responders")
b=sparsity[2,] %>% as_tibble() %>% ggplot(aes(x=value)) + geom_histogram(col="black", bins=25) + geom_vline(xintercept=50, col="red", linewidth=1) +xlab("Sparsity (%)") + ylab("Count") + ggtitle("Mid responders")
c=sparsity[3,] %>% as_tibble() %>% ggplot(aes(x=value)) + geom_histogram(col="black", bins=25) + geom_vline(xintercept=50, col="red", linewidth=1) +xlab("Sparsity (%)") + ylab("Count") + ggtitle("High responders")
ggarrange(a,b,c, nrow=1)
```

```{r process the data}
processedPloeg = processDataCube(vanderPloeg2024, sparsityThreshold=0.5, considerGroups=TRUE, groupVariable="RFgroup", centerMode=1, scaleMode=2)
```

```{r investigate num comp}
numRepetitions = 50
qualityAssessment = assessModelQuality(processedPloeg$data, minNumComponents=1, maxNumComponents=5, numRepetitions=numRepetitions, ctol=1e-6, maxit=500, numCores=12)
```

```{r check the plots}
qualityAssessment$plots$overview
qualityAssessment$plots$TCC[[3]]
```

```{r model stability}
numFolds = 50

stabilityAssessment = assessModelStability(processedPloeg, minNumComponents=1, maxNumComponents=5, numFolds=numFolds, colourCols=colourCols, legendTitles=legendTitles, xLabels=xLabels, legendColNums=legendColNums, arrangeModes=arrangeModes, numCores=12)

stabilityAssessment$modelPlots[[1]]
stabilityAssessment$modelPlots[[2]]
stabilityAssessment$modelPlots[[3]]
stabilityAssessment$modelPlots[[4]]
stabilityAssessment$modelPlots[[5]]
```

```{r select the model}
numComponents = 2
modelChoice = which(qualityAssessment$metrics$varExp[,numComponents] == max(qualityAssessment$metrics$varExp[,numComponents]))
finalModel = qualityAssessment$models[[numComponents]][[modelChoice]]
```

```{r plot the model manually}
# Plot 4B - make by hand to deal with colour feedback

# Set up colours
colours = RColorBrewer:: brewer.pal(8, "Dark2")
RF_cols = c("darkgreen","darkgoldenrod","darkred")
phylum_cols = colours[1:5]
cluster_cols = colours[-c(1:5)]
days = c(-14, 0, 2, 5, 9, 14, 21)

# Flip Fac where needed
Fac = finalModel$Fac
Fac[[1]][,1] = -1 * Fac[[1]][,1]
Fac[[3]][,1] = -1 * Fac[[3]][,1]
Fac[[1]][,2] = -1 * Fac[[1]][,1]
Fac[[2]][,2] = -1 * Fac[[2]][,2]

a = cbind(Fac[[1]], processedPloeg$mode1) %>% as_tibble() %>% arrange(RFgroup, subject) %>% mutate(index=1:nrow(.)) %>% ggplot(aes(x=index,y=`1`,fill=as.factor(RFgroup))) + geom_bar(stat="identity") + scale_fill_manual(name="Response group", values=RF_cols, labels=c("Low", "Mid", "High")) + xlab("") + ylab("Component 1") + theme(legend.position="none", text=element_text(size=12))

b = cbind(Fac[[2]], processedPloeg$mode2) %>% as_tibble() %>% arrange(Phylum, Class, Order, Family, Genus, Species, asv) %>% mutate(index=1:nrow(.)) %>% ggplot(aes(x=index,y=`1`,fill=as.factor(Phylum))) + geom_bar(stat="identity") + scale_fill_manual(name="Phylum", values=phylum_cols, labels=c("Actinobacteriota", "Bacteroidota", "Firmicutes", "Fusobacteriota", "Proteobacteria")) + xlab("") + ylab("") + theme(legend.position="none", text=element_text(size=12)) 

c = cbind(Fac[[3]], days) %>% as_tibble() %>% ggplot(aes(x=days,y=V1)) + annotate("rect", xmin=0,xmax=14,ymin=-Inf,ymax=Inf, fill="red", alpha=0.5) + geom_line() + geom_point() + xlab("") + ylab("")

d = cbind(Fac[[1]], processedPloeg$mode1) %>% as_tibble() %>% arrange(RFgroup, subject) %>% mutate(index=1:nrow(.)) %>% ggplot(aes(x=index,y=`2`,fill=as.factor(RFgroup))) + geom_bar(stat="identity") + scale_fill_manual(name="Response group", values=RF_cols, labels=c("Low", "Mid", "High")) + xlab("Subject index") + ylab("Component 2") + theme(legend.position="none", text=element_text(size=12))

e = cbind(Fac[[2]], processedPloeg$mode2) %>% as_tibble() %>% arrange(Phylum, Class, Order, Family, Genus, Species, asv) %>% mutate(index=1:nrow(.)) %>% ggplot(aes(x=index,y=`2`,fill=as.factor(Phylum))) + geom_bar(stat="identity") + scale_fill_manual(name="Phylum", values=phylum_cols, labels=c("Actinobacteriota", "Bacteroidota", "Firmicutes", "Fusobacteriota", "Proteobacteria")) + xlab("Feature index") + ylab("") + theme(legend.position="none", text=element_text(size=12)) 

f = cbind(Fac[[3]], days) %>% as_tibble() %>% ggplot(aes(x=days,y=V2)) + annotate("rect", xmin=0,xmax=14,ymin=-Inf,ymax=Inf, fill="red", alpha=0.5) + geom_line() + geom_point() + xlab("Time point [days]") + ylab("")

ggarrange(a,b,c,d,e,f)
```

```{r Import red fluorescence data}
rf_data = read.csv("./Data/Ploeg_RFdata.csv")
colnames(rf_data) = c("subject", "id", "fotonr", "day", "group", "RFgroup", "MQH", "SPS(tm)", "Area_delta_R30", "Area_delta_Rmax", "Area_delta_R30_x_Rmax", "gingiva_mean_R_over_G", "gingiva_mean_R_over_G_upper_jaw", "gingiva_mean_R_over_G_lower_jaw")
rf_data = rf_data %>% as_tibble()

rf_data[rf_data$subject == "VSTPHZ", 1] = "VSTPH2"
rf_data[rf_data$subject == "D2VZH0", 1] = "DZVZH0"
rf_data[rf_data$subject == "DLODNN", 1] = "DLODDN"
rf_data[rf_data$subject == "O3VQFX", 1] = "O3VQFQ"
rf_data[rf_data$subject == "F80LGT", 1] = "F80LGF"
rf_data[rf_data$subject == "26QQR0", 1] = "26QQrO"

rf_data2 = read.csv("./Data/Ploeg_red_fluorescence_data.csv") %>% as_tibble()
rf_data2 = rf_data2[,c(2,4,181:192)]
rf_data = rf_data %>% left_join(rf_data2)

rf = rf_data %>% select(subject, RFgroup) %>% unique()
```

```{r Import subject metadata}
age_gender = read.csv("./Data/Ploeg_subjectMetadata.csv", sep=";")
age_gender = age_gender[2:nrow(age_gender),2:ncol(age_gender)]
age_gender = age_gender %>% as_tibble() %>% filter(onderzoeksgroep == 0) %>% select(naam, leeftijd, geslacht)
colnames(age_gender) = c("subject", "age", "gender")

# Correction for incorrect subject ids
age_gender[age_gender$subject == "VSTPHZ", 1] = "VSTPH2"
age_gender[age_gender$subject == "D2VZH0", 1] = "DZVZH0"
age_gender[age_gender$subject == "DLODNN", 1] = "DLODDN"
age_gender[age_gender$subject == "O3VQFX", 1] = "O3VQFQ"
age_gender[age_gender$subject == "F80LGT", 1] = "F80LGF"
age_gender[age_gender$subject == "26QQR0", 1] = "26QQrO"

age_gender = age_gender %>% arrange(subject)
```

```{r test metadata}
normalSubjectLoadings = cbind(Fac[[1]], processedPloeg$mode1) %>% as_tibble()
transformedSubjectLoadings = transformPARAFACloadings(Fac, 2, moreOutput=TRUE)$Ftilde %>% as_tibble() %>% mutate(subject = rep(processedPloeg$mode1$subject, each=7), day = rep(c(-14,0,2,5,9,14,21),41))

uncorrectedP = matrix(0L, nrow=2, ncol=5)

# Plaque%
temp=transformedSubjectLoadings %>% left_join(rf_data %>% select(subject, day, plaquepercent))
uncorrectedP[1,1] = cor.test(temp$V1, temp$plaquepercent, method="pearson")$p.value
uncorrectedP[2,1] = cor.test(temp$V2, temp$plaquepercent, method="pearson")$p.value

# Bleeding%
temp=transformedSubjectLoadings %>% left_join(rf_data %>% select(subject, day, bomppercent))
uncorrectedP[1,2] = cor.test(temp$V1, temp$bomppercent, method="pearson")$p.value
uncorrectedP[2,2] = cor.test(temp$V2, temp$bomppercent, method="pearson")$p.value

# RF%
temp=transformedSubjectLoadings %>% left_join(rf_data %>% select(subject, day, Area_delta_R30))
uncorrectedP[1,3] = cor.test(temp$V1, temp$Area_delta_R30, method="pearson")$p.value
uncorrectedP[2,3] = cor.test(temp$V2, temp$Area_delta_R30, method="pearson")$p.value

# Gender
partA = normalSubjectLoadings %>% left_join(age_gender) %>% select(1,2,gender) %>% filter(gender==1)
partB = normalSubjectLoadings %>% left_join(age_gender) %>% select(1,2,gender) %>% filter(gender==2)

uncorrectedP[1,4] = t.test(partA$`1`, partB$`1`)$p.value # Not what I would do nowadays, but this is what is in the TIFN paper
uncorrectedP[2,4] = t.test(partA$`2`, partB$`2`)$p.value

# Age
temp = normalSubjectLoadings %>% left_join(age_gender) %>% select(1,2,age)
uncorrectedP[1,5] = cor.test(temp$`1`, temp$age, method="pearson")$p.value
uncorrectedP[2,5] = cor.test(temp$`2`, temp$age, method="pearson")$p.value

correctedP = matrix(p.adjust(uncorrectedP, "BH"), nrow=2, ncol=5)
correctedP
```


```{r filter features for clustering}
conLoad = function(X, model, mode, numComponents){
  I = dim(X)[1]
  J = dim(X)[2]
  K = dim(X)[3]
  
  if(mode == 1){
    Z = multiway::krprod(model[[3]], model[[2]])
    congruences = matrix(0, nrow=I, ncol=numComponents)
    
    for(f in 1:numComponents){
      vectZ = c(Z[,f])
      b = model[[2]][,f]
      c = model[[3]][,f]
      
      for(i in 1:I){
        Xi = X[i,,]
        vectX = c(Xi)
        congruences[i,f] = multiway::congru(vectZ, vectX)
      }
    }
  }
  else if(mode == 2){
    Z = multiway::krprod(as.matrix(model[[3]]), as.matrix(model[[1]]))
    congruences = matrix(0, nrow=J, ncol=numComponents)
    
    for(f in 1:numComponents){
      vectZ = c(Z[,f])
      for(j in 1:J){
        vectX = c(X[,j,])
        mask = !is.na(vectX)
        congruences[j,f] = multiway::congru(vectZ[mask], vectX[mask])
      }
    }
  }
  else if(mode == 3){
    Z = multiway::krprod(model[[2]], model[[1]])
    congruences = matrix(0, nrow=K, ncol=numComponents)
    
    for(f in 1:numComponents){
      vectZ = c(Z[,f])
      for(k in 1:K){
        vectX = c(X[,,k])
        congruences[k,f] = multiway::congru(vectZ, vectX)
      }
    }
  }
  return(congruences)
}

# Lazy solution to getting a long matrix
I = dim(processedPloeg$data)[1]
J = dim(processedPloeg$data)[2]
K = dim(processedPloeg$data)[3]
X_long = processedPloeg$data[,,1]
for(k in 2:K){
  X_long = rbind(X_long, processedPloeg$data[,,k])
}
X_wide = matrix(processedPloeg$data, I, J*K)
Xhat = reinflateTensor(Fac[[1]], Fac[[2]], Fac[[3]])

# Determine variance explained
featuresVarExp = 1:dim(Xhat)[2]
modelVarExp = calculateVarExp(Fac, processedPloeg$data)

for(i in 1:dim(Xhat)[2]){
  featuresVarExp[i] = multiway::sumsq(Xhat[,i,], na.rm=TRUE) / multiway::sumsq(processedPloeg$data[,i,], na.rm=TRUE)
}

# Determine congruence
fakeFac = list("A"=Fac[[1]], "B"=Fac[[2]], "C"=Fac[[3]])
featureCongruences = conLoad(processedPloeg$data, fakeFac, 2, 2)

# Establish feature mask
varExpThreshold = modelVarExp
congruenceThreshold = 0.4
featureMask = (featuresVarExp >= varExpThreshold) | (rowSums(featureCongruences>=congruenceThreshold) >= 1)
```

```{r cluster features based on modelled data}
Xhat_filtered = Xhat[,featureMask,]

I = dim(Xhat_filtered)[1]
J = dim(Xhat_filtered)[2]
K = dim(Xhat_filtered)[3]

# Lazy solution to getting a long matrix
Xhat_filtered_long = Xhat_filtered[,,1]
for(k in 2:K){
  Xhat_filtered_long = rbind(Xhat_filtered_long, Xhat_filtered[,,k])
}

# Clustering diagnostics
a = fviz_nbclust(t(Xhat_filtered_long), pam, method="wss")
b = fviz_nbclust(t(Xhat_filtered_long), pam, method="silhouette")
c = fviz_nbclust(t(Xhat_filtered_long), pam, method="gap_stat")
ggarrange(a,b,c, nrow=3)

# Cluster
set.seed(1)
numClusters = 2
clusteringResult = pam(t(Xhat_filtered_long), numClusters, nstart=50)
result = processedPloeg$mode2[featureMask,] %>% as_tibble() %>% mutate(cluster=clusteringResult$clustering)

clusteredFeatures = cbind(transformPARAFACloadings(Fac, 2), processedPloeg$mode2) %>% as_tibble() %>% left_join(result) %>% mutate(name = paste0(Genus, " ", Species))
clusteredFeatures[is.na(clusteredFeatures$cluster),"name"] = NA
clusteredFeatures[is.na(clusteredFeatures$Genus),"name"] = NA
clusteredFeatures[is.na(clusteredFeatures$Species),"name"] = NA
clusteredFeatures %>% ggplot(aes(x=`1`,y=`2`,col=as.factor(cluster))) + geom_point() + xlab("Feature mode, component 1 (transformed)") + ylab("Feature mode, component 2 (transformed)") + scale_color_manual(name = "Cluster", labels=c("1","2","3","Not clustered"), values=c("#F8766D","#00BA38","#619CFF")) + theme(legend.position="bottom",text=element_text(size=14))

clusteredFeatures %>% ggplot(aes(x=`1`,y=`2`,col=as.factor(cluster), label=name)) + geom_point(size=3) + xlab("Feature mode, component 1 (transformed)") + ylab("Feature mode, component 2 (transformed)") + scale_color_manual(name = "Cluster", labels=c("1","2","Not clustered"), values=hue_pal()(2)) + theme(legend.position="bottom",text=element_text(size=14)) + geom_text_repel()
```

```{r relabs plots of clusters}
microbiome.raw = read.csv("./Data/Ploeg_count-table.tsv", sep="\t")
taxa = read.csv("./Data/Ploeg_taxonomic-classification.tsv", sep="\t")
selectedIndividuals = microbiome.raw %>% as_tibble() %>% filter(group == "control") %>% select(subject) %>% pull %>% unique

countData = microbiome.raw %>% as_tibble() %>% filter(niche == "upper jaw, lingual", group == "control")
countData.numeric = countData %>% select(-sample,-subject,-visit,-group,-niche)
relAbs = sweep(countData.numeric, 1, rowSums(countData.numeric), FUN="/")
timepoints = c(-14,0,2,5,9,14,21)

clusterStr = c("Cluster 1", "Cluster 2")
relAbs %>% as_tibble() %>% mutate(subject=countData$subject,timepoint=timepoints[countData$visit]) %>% pivot_longer(-c(subject,timepoint)) %>% left_join(rf) %>% left_join(clusteredFeatures, by=c("name"="asv")) %>% filter(cluster != "NA") %>% select(subject,timepoint,cluster,name,RFgroup,value) %>% group_by(subject,timepoint,cluster) %>% summarize(s=sum(value)) %>% left_join(rf) %>% ungroup() %>% filter(RFgroup != 1) %>% group_by(RFgroup,timepoint,cluster) %>% summarize(m=mean(s,na.rm=TRUE),v=plotrix::std.error(s,na.rm=TRUE)) %>% ungroup() %>% mutate(cluster_str = clusterStr[cluster]) %>% ggplot(aes(x=as.factor(timepoint),y=m,col=as.factor(RFgroup),group=as.factor(RFgroup))) + facet_grid(cols=vars(cluster_str)) + geom_line() + geom_errorbar(aes(ymax=m+v,ymin=m-v,width=.2)) + geom_point() + xlab("Time point [days]") + ylab("Sum of ASVs per group (mean +/- SEM)") + scale_color_manual(name="Response group",labels=c("Low responders", "High responders"),values=RF_cols[c(1,3)]) + theme(legend.position="none",text=element_text(size=14))
```

```{r permutation testing of the relabs}
featureClustering = clusteredFeatures %>% mutate(group = cluster) %>% select(-cluster)

ASVgroupPermutationTest = function(nicheName, featureClustering, visitNumber, groupNumber, numPermutations){
  microbiome.numeric = microbiome.raw %>% as_tibble() %>% filter(group=="control", niche==nicheName, visit==visitNumber)
  microbiome.meta = microbiome.numeric %>% select(subject)
  microbiome.numeric = microbiome.numeric %>% select(-sample,-subject,-visit,-group,-niche)
  totalSums = rowSums(microbiome.numeric)
  relativeAbundances = sweep(microbiome.numeric, 1, totalSums, FUN="/") %>% as_tibble() %>% mutate(subject = microbiome.meta$subject)

  df = relativeAbundances %>%
    select(all_of(c(featureClustering$asv, "subject"))) %>%
    pivot_longer(-subject) %>%
    left_join(featureClustering, by=c("name"="asv")) %>%
    group_by(subject, group) %>%
    summarize(s=sum(value), .groups="drop") %>%
    ungroup() %>%
    left_join(rf, by="subject") %>%
    filter(group == groupNumber)

  dfA = df %>% filter(RFgroup==0) %>% select(s) %>% pull()
  dfB = df %>% filter(RFgroup==2) %>% select(s) %>% pull()
  #realResult = wilcox.test(dfA, dfB)$p.value
  realResult = mean(dfA) - mean(dfB)

  # Permutations
  set.seed(1)
  permutedResults = 1:numPermutations
  for(i in 1:numPermutations){
    dfA = df %>% mutate(RFgroup = sample(RFgroup)) %>% filter(RFgroup==0) %>% select(s) %>% pull()
    dfB = df %>% mutate(RFgroup = sample(RFgroup)) %>% filter(RFgroup==2) %>% select(s) %>% pull()
    #permutedResults[i] = wilcox.test(dfA, dfB)$p.value
    permutedResults[i] = mean(dfA) - mean(dfB)
  }

  Zscore = abs(realResult - mean(permutedResults)) / sd(permutedResults)

  if (realResult < 0){
    pvalue = sum(permutedResults < realResult) / numPermutations
  }
  else{
    pvalue = sum(permutedResults > realResult) / numPermutations
  }

  return(list(realResult, permutedResults, mean(permutedResults), median(permutedResults), sd(permutedResults), Zscore, pvalue))
}

uncorrectedP = rep(NA, 7*2)
iterator = 1

for(visit in 1:7){
  for(cluster in 1:2){
    uncorrectedP[iterator] = ASVgroupPermutationTest("upper jaw, lingual", featureClustering, visit, cluster, 999)[[7]]
    iterator = iterator + 1
  }
}

correctedP = p.adjust(uncorrectedP, "BH")

matrix(uncorrectedP, nrow=2, ncol=7)
matrix(correctedP, nrow=2, ncol=7)
```

```{r sensitivity analysis}
set.seed(123)

X = rTensor::as.tensor(vanderPloeg2024$data)
sparsity = calculateSparsity(vanderPloeg2024, considerGroups = TRUE, groupVariable = "RFgroup") * 100
sparsityMask = colSums(sparsity <= 50) >= 1

###### Pseudocount between 0 and 1
imp = matrix(runif(prod(X@modes)), X@modes)
imp[X@data != 0] = 0
imp = rTensor::k_fold(imp, m=1, X@modes)

newX = X + imp
newX_clr = log(newX@data)

newX_filtered = newX_clr[,sparsityMask,]
newX_cnt = multiwayCenter(newX_filtered, 1)
newX_cnt_scl = multiwayScale(newX_cnt, 2)

qualityAssessment2 = assessModelQuality(newX_cnt_scl, minNumComponents=1, maxNumComponents=3, numRepetitions=numRepetitions, ctol=1e-6, maxit=500, numCores=12)

###### Pseudocount 0.5

unfoldedX = t(rTensor::k_unfold(X, 2)@data) # unfold to J x IK matrix, then transpose
unfoldedX_clr = t(apply(unfoldedX+0.5, 1, function(x){log(x / compositions::geometricmean(x))}))
X_clr = rTensor::k_fold(t(unfoldedX_clr), m=2, X@modes)

newX_filtered = X_clr[,sparsityMask,]
newX_cnt = multiwayCenter(newX_filtered, 1)
newX_cnt_scl = multiwayScale(newX_cnt, 2)

qualityAssessment3 = assessModelQuality(newX_cnt_scl, minNumComponents=1, maxNumComponents=3, numRepetitions=numRepetitions, ctol=1e-6, maxit=500, numCores=12)

###### Pseudocount 0.1

unfoldedX = t(rTensor::k_unfold(X, 2)@data) # unfold to J x IK matrix, then transpose
unfoldedX_clr = t(apply(unfoldedX+0.1, 1, function(x){log(x / compositions::geometricmean(x))}))
X_clr = rTensor::k_fold(t(unfoldedX_clr), m=2, X@modes)

newX_filtered = X_clr[,sparsityMask,]
newX_cnt = multiwayCenter(newX_filtered, 1)
newX_cnt_scl = multiwayScale(newX_cnt, 2)

qualityAssessment4 = assessModelQuality(newX_cnt_scl, minNumComponents=1, maxNumComponents=3, numRepetitions=numRepetitions, ctol=1e-6, maxit=500, numCores=12)
```

```{r make sensitivity plot}
# Create fake input dataset with NA instead of zeroes to compare
Xna = newX_cnt_scl
Xna[vanderPloeg2024$data == 0] = NA

# Recalculate varExp
varExp1 = 1:50
varExp2 = 1:50
varExp3 = 1:50
varExp4 = 1:50
for(i in 1:50){
  varExp1[i] = calculateVarExp(qualityAssessment$models[[2]][[i]]$Fac, Xna) * 100
  varExp2[i] = calculateVarExp(qualityAssessment2$models[[2]][[i]]$Fac, Xna) * 100
  varExp3[i] = calculateVarExp(qualityAssessment3$models[[2]][[i]]$Fac, Xna) * 100
  varExp4[i] = calculateVarExp(qualityAssessment4$models[[2]][[i]]$Fac, Xna) * 100
}

my_comparisons = list(c("varExp1", 'varExp2'), c("varExp1", "varExp3"), c("varExp1", "varExp4"))
df = cbind(varExp1, varExp3, varExp4, varExp2) %>% as_tibble() %>% pivot_longer(everything()) %>% mutate(name = factor(name, levels=c("varExp1", "varExp3", "varExp4", "varExp2")))

df %>% ggplot(aes(x=as.factor(name),y=value)) + geom_boxplot() + stat_compare_means(comparisons=my_comparisons, label="p.signif") + scale_x_discrete(name="Pseudocount approach", labels=c("Pseudocount 1", "Pseudocount 0.5", "Pseudocount 0.1", "Pseudocount uniform (0,1)")) + ylab("Variation explained (%)")
```