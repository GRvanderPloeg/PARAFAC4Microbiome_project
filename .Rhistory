congruences = matrix(0, nrow=I, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(i in 1:I){
vectX = c(processedPloeg$data[i,,])
congruences[i,f] = psych::congruence(vectZ, vectX)
}
}
congruences
?rescale
# Solution for subject mode
finalModel2 = multiway::rescale(finalModel, mode="A", newscale=1, absorb="B")
Z = multiway::krprod(finalModel2$A, finalModel2$C)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = psych::congruence(vectZ, vectX)
}
}
congruences
plot(congruences[,1], congruences[,2])
# Solution for subject mode
finalModel2 = multiway::rescale(finalModel, mode="A", newscale=sqrt(1/nrow(finalModel$A)), absorb="B")
Z = multiway::krprod(finalModel2$A, finalModel2$C)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = psych::congruence(vectZ, vectX)
}
}
plot(congruences[,1], congruences[,2])
# Solution for subject mode
Z = multiway::krprod(finalModel$A, finalModel$C)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = psych::congruence(vectZ, vectX)
}
}
congruences
multiway::congru(vectZ,vectX)
# Solution for feature mode
Z = multiway::krprod(finalModel$A, finalModel$C)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = multiway::congru(vectZ, vectX)
}
}
congruences
?multiway::congru
0.1394 / congruences[1,1]
-0.2807 / congruences[2,1]
tempModel = multiway::parafac(processedPloeg$data, nfac=2, nstart=100)
Z = multiway::krprod(tempModel$A, tempModel$C)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = multiway::congru(vectZ, vectX)
}
}
congruences
write.table(finalModel$A, "vanderPloeg_A.csv", row.names=FALSE, col.names=FALSE)
write.table(finalModel$B, "vanderPloeg_B.csv", row.names=FALSE, col.names=FALSE)
write.table(finalModel$C, "vanderPloeg_C.csv", row.names=FALSE, col.names=FALSE)
write.table(Xwide, "vanderPloeg_X.csv", row.names=FALSE, col.names=FALSE)
write.table(X_wide, "vanderPloeg_X.csv", row.names=FALSE, col.names=FALSE)
vectZ
vectX
# Solution for subject mode
Z = multiway::krprod(finalModel$C, finalModel$B)
numComponents = 2
congruences = matrix(0, nrow=I, ncol=numComponents)
congruenceAlt = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
b = finalModel$B[,f]
c = finalModel$C[,f]
for(i in 1:I){
Xi = processedPloeg$data[i,,]
vectX = c(Xi)
congruences[i,f] = multiway::congru(vectZ, vectX)
congruenceAlt[i,f] = t(b) %*% Xi %*% c / sqrt( (t(b) %*% b) * (t(c) %*% c) * (t(vectX) %*% vectX))
}
}
all.equal(congruences, congruenceAlt)
# Solution for subject mode
Z = multiway::krprod(finalModel$C, finalModel$B)
numComponents = 2
congruences = matrix(0, nrow=I, ncol=numComponents)
congruenceAlt = matrix(0, nrow=I, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
b = finalModel$B[,f]
c = finalModel$C[,f]
for(i in 1:I){
Xi = processedPloeg$data[i,,]
vectX = c(Xi)
congruences[i,f] = multiway::congru(vectZ, vectX)
congruenceAlt[i,f] = t(b) %*% Xi %*% c / sqrt( (t(b) %*% b) * (t(c) %*% c) * (t(vectX) %*% vectX))
}
}
all.equal(congruences, congruenceAlt)
congruences
# Solution for feature mode
Z = multiway::krprod(finalModel$C, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = multiway::congru(vectZ, vectX)
}
}
congruences
# Solution for time mode
Z = multiway::krprod(finalModel$B, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=K, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(k in 1:K){
vectX = c(processedPloeg$data[,,k])
congruences[k,f] = multiway::congru(vectZ, vectX)
}
}
congruences
conLoad = function(X, model, mode){
if(mode == 1){
Z = multiway::krprod(finalModel$C, finalModel$B)
numComponents = 2
congruences = matrix(0, nrow=I, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
b = finalModel$B[,f]
c = finalModel$C[,f]
for(i in 1:I){
Xi = processedPloeg$data[i,,]
vectX = c(Xi)
congruences[i,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 2){
Z = multiway::krprod(finalModel$C, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 3){
Z = multiway::krprod(finalModel$B, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=K, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(k in 1:K){
vectX = c(processedPloeg$data[,,k])
congruences[k,f] = multiway::congru(vectZ, vectX)
}
}
}
}
# Lazy solution to getting a long matrix
I = dim(processedPloeg$data)[1]
J = dim(processedPloeg$data)[2]
K = dim(processedPloeg$data)[3]
X_long = processedPloeg$data[,,1]
for(k in 2:K){
X_long = rbind(X_long, processedPloeg$data[,,k])
}
X_wide = matrix(processedPloeg$data, I, J*K)
Xhat = reinflateBlock(finalModel)
# Determine variance explained
featuresVarExp = 1:dim(Xhat)[2]
modelVarExp = varExp
for(i in 1:dim(Xhat)[2]){
featuresVarExp[i] = multiway::sumsq(Xhat[,i,], na.rm=TRUE) / multiway::sumsq(processedPloeg$data[,i,], na.rm=TRUE)
}
# Determine congruence
featureCongruences = conLoad(processedPloeg$data, finalModel, 2)
featureMask = featuresVarExp >= modelVarExp | featureCongruences >= 0.4
featureMask = (featuresVarExp >= modelVarExp) | (featureCongruences >= 0.4)
sum(featureMaskl)
sum(featureMask)
featureCongruences
conLoad(processedPloeg$data, finalModel, 2)
conLoad = function(X, model, mode){
if(mode == 1){
Z = multiway::krprod(finalModel$C, finalModel$B)
numComponents = 2
congruences = matrix(0, nrow=I, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
b = finalModel$B[,f]
c = finalModel$C[,f]
for(i in 1:I){
Xi = processedPloeg$data[i,,]
vectX = c(Xi)
congruences[i,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 2){
Z = multiway::krprod(finalModel$C, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 3){
Z = multiway::krprod(finalModel$B, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=K, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(k in 1:K){
vectX = c(processedPloeg$data[,,k])
congruences[k,f] = multiway::congru(vectZ, vectX)
}
}
}
return(congruences)
}
# Lazy solution to getting a long matrix
I = dim(processedPloeg$data)[1]
J = dim(processedPloeg$data)[2]
K = dim(processedPloeg$data)[3]
X_long = processedPloeg$data[,,1]
for(k in 2:K){
X_long = rbind(X_long, processedPloeg$data[,,k])
}
X_wide = matrix(processedPloeg$data, I, J*K)
Xhat = reinflateBlock(finalModel)
# Determine variance explained
featuresVarExp = 1:dim(Xhat)[2]
modelVarExp = varExp
for(i in 1:dim(Xhat)[2]){
featuresVarExp[i] = multiway::sumsq(Xhat[,i,], na.rm=TRUE) / multiway::sumsq(processedPloeg$data[,i,], na.rm=TRUE)
}
# Determine congruence
featureCongruences = conLoad(processedPloeg$data, finalModel, 2)
featureMask = (featuresVarExp >= modelVarExp) | (featureCongruences >= 0.4)
(featureCongruences >= 0.4)
rowSums(featureCongruences>=0.4) >= 1
featureMask = (featuresVarExp >= modelVarExp) | (rowSums(featureCongruences>=0.4) >= 1)
featureMask
sum(featureMask)
library(cluster)
library(factoextra)
Xhat_filtered = Xhat[,featureMask,]
I = dim(Xhat_filtered)[1]
J = dim(Xhat_filtered)[2]
K = dim(Xhat_filtered)[3]
# Lazy solution to getting a long matrix
Xhat_filtered_long = Xhat_filtered[,,1]
for(k in 2:K){
Xhat_filtered_long = rbind(Xhat_filtered_long, Xhat_filtered[,,k])
}
# Clustering diagnostics
a = fviz_nbclust(t(Xhat_filtered_long), pam, method="wss")
b = fviz_nbclust(t(Xhat_filtered_long), pam, method="silhouette")
c = fviz_nbclust(t(Xhat_filtered_long), pam, method="gap_stat")
ggarrange(a,b,c, nrow=3)
# Cluster
set.seed(1)
numClusters = 3
clusteringResult = pam(t(Xhat_filtered_long), numClusters, nstart=50)
result = processedPloeg$mode2[featureMask,] %>% as_tibble() %>% mutate(cluster=clusteringResult$clustering)
clusteredFeatures = cbind(correctPARAFACloadings(processedPloeg, finalModel, 2), processedPloeg$mode2) %>% as_tibble() %>% left_join(result)
clusteredFeatures %>% ggplot(aes(x=`1`,y=`2`,col=as.factor(cluster))) + geom_point() + xlab("Feature mode, component 1 (transformed)") + ylab("Feature mode, component 2 (transformed)") + scale_color_manual(name = "Cluster", labels=c("1","2","3","Not clustered"), values=c("#F8766D","#00BA38","#619CFF"))
conLoad = function(X, model, mode){
if(mode == 1){
Z = multiway::krprod(finalModel$C, finalModel$B)
numComponents = 2
congruences = matrix(0, nrow=I, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
b = finalModel$B[,f]
c = finalModel$C[,f]
for(i in 1:I){
Xi = processedPloeg$data[i,,]
vectX = c(Xi)
congruences[i,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 2){
Z = multiway::krprod(finalModel$C, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 3){
Z = multiway::krprod(finalModel$B, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=K, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(k in 1:K){
vectX = c(processedPloeg$data[,,k])
congruences[k,f] = multiway::congru(vectZ, vectX)
}
}
}
return(congruences)
}
# Lazy solution to getting a long matrix
I = dim(processedPloeg$data)[1]
J = dim(processedPloeg$data)[2]
K = dim(processedPloeg$data)[3]
X_long = processedPloeg$data[,,1]
for(k in 2:K){
X_long = rbind(X_long, processedPloeg$data[,,k])
}
X_wide = matrix(processedPloeg$data, I, J*K)
Xhat = reinflateBlock(finalModel)
# Determine variance explained
featuresVarExp = 1:dim(Xhat)[2]
modelVarExp = varExp
for(i in 1:dim(Xhat)[2]){
featuresVarExp[i] = multiway::sumsq(Xhat[,i,], na.rm=TRUE) / multiway::sumsq(processedPloeg$data[,i,], na.rm=TRUE)
}
# Determine congruence
featureCongruences = conLoad(processedPloeg$data, finalModel, 2)
featureMask = (featuresVarExp >= 19.8) | (rowSums(featureCongruences>=0.4) >= 1)
sum(featureMask)
featureMask = (featuresVarExp >= 19.7) | (rowSums(featureCongruences>=0.4) >= 1)
sum(featureMask)
library(cluster)
library(factoextra)
Xhat_filtered = Xhat[,featureMask,]
I = dim(Xhat_filtered)[1]
J = dim(Xhat_filtered)[2]
K = dim(Xhat_filtered)[3]
# Lazy solution to getting a long matrix
Xhat_filtered_long = Xhat_filtered[,,1]
for(k in 2:K){
Xhat_filtered_long = rbind(Xhat_filtered_long, Xhat_filtered[,,k])
}
# Clustering diagnostics
a = fviz_nbclust(t(Xhat_filtered_long), pam, method="wss")
b = fviz_nbclust(t(Xhat_filtered_long), pam, method="silhouette")
c = fviz_nbclust(t(Xhat_filtered_long), pam, method="gap_stat")
ggarrange(a,b,c, nrow=3)
# Cluster
set.seed(1)
numClusters = 3
clusteringResult = pam(t(Xhat_filtered_long), numClusters, nstart=50)
result = processedPloeg$mode2[featureMask,] %>% as_tibble() %>% mutate(cluster=clusteringResult$clustering)
clusteredFeatures = cbind(correctPARAFACloadings(processedPloeg, finalModel, 2), processedPloeg$mode2) %>% as_tibble() %>% left_join(result)
clusteredFeatures %>% ggplot(aes(x=`1`,y=`2`,col=as.factor(cluster))) + geom_point() + xlab("Feature mode, component 1 (transformed)") + ylab("Feature mode, component 2 (transformed)") + scale_color_manual(name = "Cluster", labels=c("1","2","3","Not clustered"), values=c("#F8766D","#00BA38","#619CFF"))
c
a
featuresVarExp
featureMask = (featuresVarExp >= 0.197) | (rowSums(featureCongruences>=0.4) >= 1)
sum(featureMask)
featureMask = (featuresVarExp >= 0.1975) | (rowSums(featureCongruences>=0.4) >= 1)
sum(featureMask)
library(cluster)
library(factoextra)
Xhat_filtered = Xhat[,featureMask,]
I = dim(Xhat_filtered)[1]
J = dim(Xhat_filtered)[2]
K = dim(Xhat_filtered)[3]
# Lazy solution to getting a long matrix
Xhat_filtered_long = Xhat_filtered[,,1]
for(k in 2:K){
Xhat_filtered_long = rbind(Xhat_filtered_long, Xhat_filtered[,,k])
}
# Clustering diagnostics
a = fviz_nbclust(t(Xhat_filtered_long), pam, method="wss")
b = fviz_nbclust(t(Xhat_filtered_long), pam, method="silhouette")
c = fviz_nbclust(t(Xhat_filtered_long), pam, method="gap_stat")
ggarrange(a,b,c, nrow=3)
# Cluster
set.seed(1)
numClusters = 3
clusteringResult = pam(t(Xhat_filtered_long), numClusters, nstart=50)
result = processedPloeg$mode2[featureMask,] %>% as_tibble() %>% mutate(cluster=clusteringResult$clustering)
clusteredFeatures = cbind(correctPARAFACloadings(processedPloeg, finalModel, 2), processedPloeg$mode2) %>% as_tibble() %>% left_join(result)
clusteredFeatures %>% ggplot(aes(x=`1`,y=`2`,col=as.factor(cluster))) + geom_point() + xlab("Feature mode, component 1 (transformed)") + ylab("Feature mode, component 2 (transformed)") + scale_color_manual(name = "Cluster", labels=c("1","2","3","Not clustered"), values=c("#F8766D","#00BA38","#619CFF"))
conLoad = function(X, model, mode){
if(mode == 1){
Z = multiway::krprod(finalModel$C, finalModel$B)
numComponents = 2
congruences = matrix(0, nrow=I, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
b = finalModel$B[,f]
c = finalModel$C[,f]
for(i in 1:I){
Xi = processedPloeg$data[i,,]
vectX = c(Xi)
congruences[i,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 2){
Z = multiway::krprod(finalModel$C, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=J, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(j in 1:J){
vectX = c(processedPloeg$data[,j,])
congruences[j,f] = multiway::congru(vectZ, vectX)
}
}
}
else if(mode == 3){
Z = multiway::krprod(finalModel$B, finalModel$A)
numComponents = 2
congruences = matrix(0, nrow=K, ncol=numComponents)
for(f in 1:numComponents){
vectZ = c(Z[,f])
for(k in 1:K){
vectX = c(processedPloeg$data[,,k])
congruences[k,f] = multiway::congru(vectZ, vectX)
}
}
}
return(congruences)
}
# Lazy solution to getting a long matrix
I = dim(processedPloeg$data)[1]
J = dim(processedPloeg$data)[2]
K = dim(processedPloeg$data)[3]
X_long = processedPloeg$data[,,1]
for(k in 2:K){
X_long = rbind(X_long, processedPloeg$data[,,k])
}
X_wide = matrix(processedPloeg$data, I, J*K)
Xhat = reinflateBlock(finalModel)
# Determine variance explained
featuresVarExp = 1:dim(Xhat)[2]
modelVarExp = varExp
for(i in 1:dim(Xhat)[2]){
featuresVarExp[i] = multiway::sumsq(Xhat[,i,], na.rm=TRUE) / multiway::sumsq(processedPloeg$data[,i,], na.rm=TRUE)
}
# Determine congruence
featureCongruences = conLoad(processedPloeg$data, finalModel, 2)
# Establish feature mask
varExpThreshold = modelVarExp
congruenceThreshold = 0.4
featureMask = (featuresVarExp >= varExpThreshold) | (rowSums(featureCongruences>=congruenceThreshold) >= 1)
library(cluster)
library(factoextra)
Xhat_filtered = Xhat[,featureMask,]
I = dim(Xhat_filtered)[1]
J = dim(Xhat_filtered)[2]
K = dim(Xhat_filtered)[3]
# Lazy solution to getting a long matrix
Xhat_filtered_long = Xhat_filtered[,,1]
for(k in 2:K){
Xhat_filtered_long = rbind(Xhat_filtered_long, Xhat_filtered[,,k])
}
# Clustering diagnostics
a = fviz_nbclust(t(Xhat_filtered_long), pam, method="wss")
b = fviz_nbclust(t(Xhat_filtered_long), pam, method="silhouette")
c = fviz_nbclust(t(Xhat_filtered_long), pam, method="gap_stat")
ggarrange(a,b,c, nrow=3)
# Cluster
set.seed(1)
numClusters = 3
clusteringResult = pam(t(Xhat_filtered_long), numClusters, nstart=50)
result = processedPloeg$mode2[featureMask,] %>% as_tibble() %>% mutate(cluster=clusteringResult$clustering)
clusteredFeatures = cbind(correctPARAFACloadings(processedPloeg, finalModel, 2), processedPloeg$mode2) %>% as_tibble() %>% left_join(result)
clusteredFeatures %>% ggplot(aes(x=`1`,y=`2`,col=as.factor(cluster))) + geom_point() + xlab("Feature mode, component 1 (transformed)") + ylab("Feature mode, component 2 (transformed)") + scale_color_manual(name = "Cluster", labels=c("1","2","3","Not clustered"), values=c("#F8766D","#00BA38","#619CFF"))
ggarrange(a,b,c, nrow=3)
clusteredFeatures %>% ggplot(aes(x=`1`,y=`2`,col=as.factor(cluster))) + geom_point() + xlab("Feature mode, component 1 (transformed)") + ylab("Feature mode, component 2 (transformed)") + scale_color_manual(name = "Cluster", labels=c("1","2","3","Not clustered"), values=c("#F8766D","#00BA38","#619CFF"))
microbiome.raw = read.csv("./vanderPloeg2024/Homogenized data analysis/0. Raw data input/20221005_wp2/count-table.tsv", sep="\t")
taxa = read.csv("./vanderPloeg2024/Homogenized data analysis/0. Raw data input/20221005_wp2/taxonomic-classification.tsv", sep="\t")
selectedIndividuals = microbiome.raw %>% as_tibble() %>% filter(group == "control") %>% select(subject) %>% pull %>% unique
countData = microbiome.raw %>% as_tibble() %>% filter(niche == "upper jaw, lingual", group == "control")
countData.numeric = countData %>% select(-sample,-subject,-visit,-group,-niche)
relAbs = sweep(countData.numeric, 1, rowSums(countData.numeric), FUN="/")
timepoints = c(-14,0,2,5,9,14,21)
relAbs %>% as_tibble() %>% mutate(subject=countData$subject,timepoint=timepoints[countData$visit]) %>% pivot_longer(-c(subject,timepoint)) %>% left_join(rf) %>% left_join(clusteredFeatures, by=c("name"="asv")) %>% filter(cluster != "NA") %>% select(subject,timepoint,cluster,name,RFgroup,value) %>% group_by(subject,timepoint,cluster) %>% summarize(s=sum(value)) %>% left_join(rf) %>% ungroup() %>% filter(RFgroup != 1) %>% group_by(RFgroup,timepoint,cluster) %>% summarize(m=mean(s,na.rm=TRUE),v=plotrix::std.error(s,na.rm=TRUE)) %>% ungroup() %>% ggplot(aes(x=as.factor(timepoint),y=m,col=as.factor(RFgroup),group=as.factor(RFgroup))) + facet_grid(cols=vars(cluster)) + geom_line() + geom_errorbar(aes(ymax=m+v,ymin=m-v,width=.2)) + geom_point() + theme(legend.position="none",text=element_text(size=14)) + xlab("Time point [days]") + ylab("Sum of ASVs per group (mean +/- SEM)")
relAbs %>% as_tibble() %>% mutate(subject=countData$subject,timepoint=timepoints[countData$visit]) %>% pivot_longer(-c(subject,timepoint)) %>% left_join(rf) %>% left_join(clusteredFeatures, by=c("name"="asv")) %>% filter(cluster != "NA") %>% select(subject,timepoint,cluster,name,RFgroup,value) %>% group_by(subject,timepoint,cluster) %>% summarize(s=sum(value)) %>% left_join(rf) %>% ungroup() %>% filter(RFgroup != 1) %>% group_by(RFgroup,timepoint,cluster) %>% summarize(m=mean(s,na.rm=TRUE),v=plotrix::std.error(s,na.rm=TRUE)) %>% ungroup() %>% ggplot(aes(x=as.factor(timepoint),y=m,col=as.factor(RFgroup),group=as.factor(RFgroup))) + facet_grid(cols=vars(cluster)) + geom_line() + geom_errorbar(aes(ymax=m+v,ymin=m-v,width=.2)) + geom_point() + theme(legend.position="none",text=element_text(size=14)) + xlab("Time point [days]") + ylab("Sum of ASVs per group (mean +/- SEM)")
