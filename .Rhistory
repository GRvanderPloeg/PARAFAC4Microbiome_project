}
# Prepare modelling parameters per timepoint and simulate.
params = list()
simResults = list()
for(i in 1:numTimepoints){
for(j in 1:numSubjectGroups){
param = list()
param$intensity = c()
param$variability = c()
for(k in 1:numFeatureGroups){
param$intensity = c(param$intensity, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
param$variability = c(param$variability, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
}
param$variability = param$variability * relativeNoise
param$lib_size = round(rnorm(numSubjectsPerGroup[j], mean=avgLibSize, sd=stdLibSize))
params[[j]] = param
}
names(params) = paste0("subjectGroup_", 1:length(numSubjects))
simResults[[i]] = metaSPARSim(params)
}
# Prepare output
result = data.frame()
for(i in 1:numTimepoints){
result = rbind(result, t(simResults[[i]]$counts))
}
result$timepoint = rep(1:numTimepoints, each=sum(numSubjectsPerGroup))
return(list(abundanceTable, result))
}
subjectLoadings = rbind(c(0.3, 0.8),
c(0.8, 0.2))
featureLoadings = rbind(c(1.0, 0.1),
c(0.1, 1.0))
timeLoadings = rbind(c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9),
c(1.0, 1.0, 1.0, 1.0, 0.5, 0.1, 0.1, 0.1, 0.1))
numSubjectsPerGroup = c(5, 5) # group 1, group 2
numFeaturesPerGroup = c(20, 20) # group 1, group 2
relativeNoise = 0.75
avgLibSize = 25000
stdLibSize = 5000
outcome = simulateCountData(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize)
outcome
write.table(outcome[[2]], "./simData.csv", sep=",", row.names=FALSE, col.names=TRUE)
1:sum(numSubjectsPerGroup)
rep(c("A", "B"), each=numTimepoints)
?rep
LETTERS[1]
numSubjectsPerGroup
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:numSubjectGroups){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j]), numSubjectsPerGroup[j])
}
}
numSubjectGroups = length(numSubjectsPerGroup)
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:numSubjectGroups){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j]), numSubjectsPerGroup[j])
}
}
subjectMetaData
subjectMetadata
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:numSubjectGroups){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j], numSubjectsPerGroup[j]))
}
}
subjectMetadata
dim(outcome[[2]])
length(subjectMetadata)
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:numSubjectGroups){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j], numSubjectsPerGroup[j]))
}
}
subjectMetadata = cbind(1:sum(numSubjectsPerGroup), subjectMetadata)
subjectMetadata
featureMetadata = c()
for(i in 1:numFeatureGroups){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
numFeaturesPerGroup = c(20, 20) # group 1, group 2
featureMetadata = c()
for(i in 1:numFeatureGroups){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
numFeatureGroups = length(numFeaturesPerGroup)
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:length(numSubjectsPerGroup)){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j], numSubjectsPerGroup[j]))
}
}
subjectMetadata = cbind(1:sum(numSubjectsPerGroup), subjectMetadata)
subjectMetadata
featureMetadata = c()
for(i in 1:length(numFeaturesPerGroup)){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
featureMetadata
featureMetadata = c()
for(i in 1:length(numFeaturesPerGroup)){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
featureMetadata = cbind(1:sum(numFeaturesPerGroup), featureMetadata)
# Simulate microbiome count data with metaSPARSim
library(metaSPARSim)
rlang::global_entrace()
options(rlang_backtrace_on_warning_report = "full")
options(rlang_backtrace_on_error_report = "full")
simulateCountData = function(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize){
# Number of components is assumed to be the same for all modes, otherwise
# PARAFAC would not be an appropriate model to use anyway.
numTimepoints = ncol(timeLoadings)
numComponents = nrow(subjectLoadings)
numSubjectGroups = length(numSubjectsPerGroup)
numFeatureGroups = length(numFeaturesPerGroup)
# Abundance table is initialized empty (list items are timepoints)
abundanceTable = list()
for(i in 1:numTimepoints){
abundanceTable[[i]] = matrix(0L, nrow = ncol(subjectLoadings), ncol = ncol(featureLoadings))
}
# Generate abundances by mixing all components together.
for(i in 1:numComponents){
subjectLoading = subjectLoadings[i,]
featureLoading = featureLoadings[i,]
timeLoading = timeLoadings[i,]
for(j in 1:numTimepoints){
pattern = (subjectLoading %*% t(featureLoading)) * timeLoading[j]
abundanceTable[[j]] = abundanceTable[[j]] + pattern
}
}
# This is normalized to be sum 1 for easy interpretation.
for(i in 1:numTimepoints){
abundanceMatrix = abundanceTable[[i]]
for(j in 1:nrow(abundanceMatrix)){
abundanceTable[[i]][j,] = abundanceTable[[i]][j,] / sum(abundanceTable[[i]][j,])
}
}
# Prepare modelling parameters per timepoint and simulate.
params = list()
simResults = list()
for(i in 1:numTimepoints){
for(j in 1:numSubjectGroups){
param = list()
param$intensity = c()
param$variability = c()
for(k in 1:numFeatureGroups){
param$intensity = c(param$intensity, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
param$variability = c(param$variability, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
}
param$variability = param$variability * relativeNoise
param$lib_size = round(rnorm(numSubjectsPerGroup[j], mean=avgLibSize, sd=stdLibSize))
params[[j]] = param
}
names(params) = paste0("subjectGroup_", 1:length(numSubjects))
simResults[[i]] = metaSPARSim(params)
}
# Prepare output
result = data.frame()
for(i in 1:numTimepoints){
result = rbind(result, t(simResults[[i]]$counts))
}
return(list(abundanceTable, result))
}
subjectLoadings = rbind(c(0.3, 0.8),
c(0.8, 0.2))
featureLoadings = rbind(c(1.0, 0.1),
c(0.1, 1.0))
timeLoadings = rbind(c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9),
c(1.0, 1.0, 1.0, 1.0, 0.5, 0.1, 0.1, 0.1, 0.1))
numSubjectsPerGroup = c(5, 5) # group 1, group 2
numFeaturesPerGroup = c(20, 20) # group 1, group 2
relativeNoise = 0.75
avgLibSize = 25000
stdLibSize = 5000
outcome = simulateCountData(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize)
# Construct additional metadata (especially useful in unbalanced cases)
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:length(numSubjectsPerGroup)){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j], numSubjectsPerGroup[j]))
}
}
subjectMetadata = cbind(1:sum(numSubjectsPerGroup), subjectMetadata)
featureMetadata = c()
for(i in 1:length(numFeaturesPerGroup)){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
featureMetadata = cbind(1:sum(numFeaturesPerGroup), featureMetadata)
# Save data
write.table(subjectMetadata, " ./simSubjectData.csv", sep=",", row.names=FALSE, col.names=FALSE)
subjectMetadata
write.table(subjectMetadata, " ./simSubjectData.csv", sep=",", row.names=FALSE, col.names=FALSE)
?write.table
write.table(as.matrix(subjectMetadata), " ./simSubjectData.csv", sep=",", row.names=FALSE, col.names=FALSE)
rlang::last_trace()
getwd()
# Save data
write.table(subjectMetadata, " ./simSubjectData.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureMetadata, " ./simFeatureData.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(subjectLoadings, "./subjectLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureLoadings, "./featureLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(timeLoadings, "./timeLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(outcome[[2]], "./simData.csv", sep=",", row.names=FALSE, col.names=TRUE)
as.data.frame(subjectMetadata)
# Save data
write.table(as.data.frame(subjectMetadata), " ./simSubjectData.csv", sep=",", row.names=FALSE, col.names=FALSE)
type(subjectLoadings)
type(subjectMetadata)
# Save data
write.csv(as.data.frame(subjectMetadata), " ./simSubjectData.csv", sep=",", row.names=FALSE, col.names=FALSE)
# Save data
write.csv(as.data.frame(subjectMetadata), " ./temp.csv", sep=",", row.names=FALSE, col.names=FALSE)
# Save data
write.csv(subjectMetadata, "./subjectMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureMetadata, "./featureMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
# Save data
write.table(subjectMetadata, "./subjectMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
# Simulate microbiome count data with metaSPARSim
library(metaSPARSim)
rlang::global_entrace()
options(rlang_backtrace_on_warning_report = "full")
options(rlang_backtrace_on_error_report = "full")
simulateCountData = function(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize){
# Number of components is assumed to be the same for all modes, otherwise
# PARAFAC would not be an appropriate model to use anyway.
numTimepoints = ncol(timeLoadings)
numComponents = nrow(subjectLoadings)
numSubjectGroups = length(numSubjectsPerGroup)
numFeatureGroups = length(numFeaturesPerGroup)
# Abundance table is initialized empty (list items are timepoints)
abundanceTable = list()
for(i in 1:numTimepoints){
abundanceTable[[i]] = matrix(0L, nrow = ncol(subjectLoadings), ncol = ncol(featureLoadings))
}
# Generate abundances by mixing all components together.
for(i in 1:numComponents){
subjectLoading = subjectLoadings[i,]
featureLoading = featureLoadings[i,]
timeLoading = timeLoadings[i,]
for(j in 1:numTimepoints){
pattern = (subjectLoading %*% t(featureLoading)) * timeLoading[j]
abundanceTable[[j]] = abundanceTable[[j]] + pattern
}
}
# This is normalized to be sum 1 for easy interpretation.
for(i in 1:numTimepoints){
abundanceMatrix = abundanceTable[[i]]
for(j in 1:nrow(abundanceMatrix)){
abundanceTable[[i]][j,] = abundanceTable[[i]][j,] / sum(abundanceTable[[i]][j,])
}
}
# Prepare modelling parameters per timepoint and simulate.
params = list()
simResults = list()
for(i in 1:numTimepoints){
for(j in 1:numSubjectGroups){
param = list()
param$intensity = c()
param$variability = c()
for(k in 1:numFeatureGroups){
param$intensity = c(param$intensity, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
param$variability = c(param$variability, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
}
param$variability = param$variability * relativeNoise
param$lib_size = round(rnorm(numSubjectsPerGroup[j], mean=avgLibSize, sd=stdLibSize))
params[[j]] = param
}
names(params) = paste0("subjectGroup_", 1:length(numSubjects))
simResults[[i]] = metaSPARSim(params)
}
# Prepare output
result = data.frame()
for(i in 1:numTimepoints){
result = rbind(result, t(simResults[[i]]$counts))
}
return(list(abundanceTable, result))
}
# Rows: subject, features; columns: components
subjectLoadings = rbind(c(1.0, 0.01, 0.01),
c(0.01, 1.0, 0.01))
featureLoadings = rbind(c(1.0, 0.01, 0.01),
c(0.01, 1.0, 0.01))
timeLoadings = rbind(c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9),
c(1.0, 1.0, 1.0, 1.0, 0.5, 0.1, 0.1, 0.1, 0.1),
c(1.0, 1.0, 0.1, 0.1, 0.1, 0.1, 0.1, 1.0, 1.0))
numSubjectsPerGroup = c(5, 5)
numFeaturesPerGroup = c(20, 20)
relativeNoise = 0.5
avgLibSize = 25000
stdLibSize = 5000
outcome = simulateCountData(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize)
# Construct additional metadata (especially useful in unbalanced cases)
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:length(numSubjectsPerGroup)){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j], numSubjectsPerGroup[j]))
}
}
subjectMetadata = cbind(1:sum(numSubjectsPerGroup), subjectMetadata)
featureMetadata = c()
for(i in 1:length(numFeaturesPerGroup)){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
featureMetadata = cbind(1:sum(numFeaturesPerGroup), featureMetadata)
# Save data
write.table(subjectMetadata, "./subjectMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureMetadata, "./featureMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(subjectLoadings, "./subjectLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureLoadings, "./featureLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(timeLoadings, "./timeLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(outcome[[2]], "./simData.csv", sep=",", row.names=FALSE, col.names=TRUE)
# Simulate microbiome count data with metaSPARSim
library(metaSPARSim)
rlang::global_entrace()
options(rlang_backtrace_on_warning_report = "full")
options(rlang_backtrace_on_error_report = "full")
simulateCountData = function(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize){
# Number of components is assumed to be the same for all modes, otherwise
# PARAFAC would not be an appropriate model to use anyway.
numTimepoints = ncol(timeLoadings)
numComponents = nrow(subjectLoadings)
numSubjectGroups = length(numSubjectsPerGroup)
numFeatureGroups = length(numFeaturesPerGroup)
# Abundance table is initialized empty (list items are timepoints)
abundanceTable = list()
for(i in 1:numTimepoints){
abundanceTable[[i]] = matrix(0L, nrow = ncol(subjectLoadings), ncol = ncol(featureLoadings))
}
# Generate abundances by mixing all components together.
for(i in 1:numComponents){
subjectLoading = subjectLoadings[i,]
featureLoading = featureLoadings[i,]
timeLoading = timeLoadings[i,]
for(j in 1:numTimepoints){
pattern = (subjectLoading %*% t(featureLoading)) * timeLoading[j]
abundanceTable[[j]] = abundanceTable[[j]] + pattern
}
}
# This is normalized to be sum 1 for easy interpretation.
for(i in 1:numTimepoints){
abundanceMatrix = abundanceTable[[i]]
for(j in 1:nrow(abundanceMatrix)){
abundanceTable[[i]][j,] = abundanceTable[[i]][j,] / sum(abundanceTable[[i]][j,])
}
}
# Prepare modelling parameters per timepoint and simulate.
params = list()
simResults = list()
for(i in 1:numTimepoints){
print(paste0("Timepoint: ", i))
for(j in 1:numSubjectGroups){
param = list()
param$intensity = c()
param$variability = c()
for(k in 1:numFeatureGroups){
param$intensity = c(param$intensity, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
param$variability = c(param$variability, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
}
param$variability = param$variability * relativeNoise
param$lib_size = round(rnorm(numSubjectsPerGroup[j], mean=avgLibSize, sd=stdLibSize))
params[[j]] = param
}
names(params) = paste0("subjectGroup_", 1:length(numSubjects))
simResults[[i]] = metaSPARSim(params)
}
# Prepare output
result = data.frame()
for(i in 1:numTimepoints){
result = rbind(result, t(simResults[[i]]$counts))
}
return(list(abundanceTable, result))
}
# Rows: subject, features; columns: components
subjectLoadings = rbind(c(1.0, 0.01),
c(0.01, 1.0))
featureLoadings = rbind(c(1.0, 0.01),
c(0.01, 1.0))
timeLoadings = rbind(c(1.0, 1.0, 1.0, 1.0, 0.5, 0.1, 0.1, 0.1, 0.1),
c(1.0, 1.0, 0.1, 0.1, 0.1, 0.1, 0.1, 1.0, 1.0))
numSubjectsPerGroup = c(10, 10)
numFeaturesPerGroup = c(200, 200)
relativeNoise = 0.01
avgLibSize = 25000
stdLibSize = 5000
outcome = simulateCountData(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize)
# Construct additional metadata (especially useful in unbalanced cases)
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:length(numSubjectsPerGroup)){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j], numSubjectsPerGroup[j]))
}
}
subjectMetadata = cbind(1:sum(numSubjectsPerGroup), subjectMetadata)
featureMetadata = c()
for(i in 1:length(numFeaturesPerGroup)){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
featureMetadata = cbind(1:sum(numFeaturesPerGroup), featureMetadata)
# Save data
write.table(subjectMetadata, "./subjectMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureMetadata, "./featureMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(subjectLoadings, "./subjectLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureLoadings, "./featureLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(timeLoadings, "./timeLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(outcome[[2]], "./simData.csv", sep=",", row.names=FALSE, col.names=TRUE)
# Simulate microbiome count data with metaSPARSim
library(metaSPARSim)
rlang::global_entrace()
options(rlang_backtrace_on_warning_report = "full")
options(rlang_backtrace_on_error_report = "full")
simulateCountData = function(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize){
# Number of components is assumed to be the same for all modes, otherwise
# PARAFAC would not be an appropriate model to use anyway.
numTimepoints = ncol(timeLoadings)
numComponents = nrow(subjectLoadings)
numSubjectGroups = length(numSubjectsPerGroup)
numFeatureGroups = length(numFeaturesPerGroup)
# Abundance table is initialized empty (list items are timepoints)
abundanceTable = list()
for(i in 1:numTimepoints){
abundanceTable[[i]] = matrix(0L, nrow = ncol(subjectLoadings), ncol = ncol(featureLoadings))
}
# Generate abundances by mixing all components together.
for(i in 1:numComponents){
subjectLoading = subjectLoadings[i,]
featureLoading = featureLoadings[i,]
timeLoading = timeLoadings[i,]
for(j in 1:numTimepoints){
pattern = (subjectLoading %*% t(featureLoading)) * timeLoading[j]
abundanceTable[[j]] = abundanceTable[[j]] + pattern
}
}
# This is normalized to be sum 1 for easy interpretation.
for(i in 1:numTimepoints){
abundanceMatrix = abundanceTable[[i]]
for(j in 1:nrow(abundanceMatrix)){
abundanceTable[[i]][j,] = abundanceTable[[i]][j,] / sum(abundanceTable[[i]][j,])
}
}
# Prepare modelling parameters per timepoint and simulate.
params = list()
simResults = list()
for(i in 1:numTimepoints){
print(paste0("Timepoint: ", i))
for(j in 1:numSubjectGroups){
param = list()
param$intensity = c()
param$variability = c()
for(k in 1:numFeatureGroups){
param$intensity = c(param$intensity, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
param$variability = c(param$variability, rep(abundanceTable[[i]][j,k], numFeaturesPerGroup[k]))
}
param$variability = param$variability * relativeNoise
param$lib_size = round(rnorm(numSubjectsPerGroup[j], mean=avgLibSize, sd=stdLibSize))
params[[j]] = param
}
names(params) = paste0("subjectGroup_", 1:length(numSubjects))
simResults[[i]] = metaSPARSim(params)
}
# Prepare output
result = data.frame()
for(i in 1:numTimepoints){
result = rbind(result, t(simResults[[i]]$counts))
}
return(list(abundanceTable, result))
}
# Rows: subject, features; columns: components
subjectLoadings = rbind(c(1.0, 0.01),
c(0.01, 1.0))
featureLoadings = rbind(c(1.0, 0.01),
c(0.01, 1.0))
timeLoadings = rbind(c(1.0, 1.0, 1.0, 1.0, 0.5, 0.1, 0.1, 0.1, 0.1),
c(0.1, 0.1, 0.1, 0.1, 0.5, 1.0, 1.0, 1.0, 1.0))
numSubjectsPerGroup = c(10, 10)
numFeaturesPerGroup = c(200, 200)
relativeNoise = 0.01
avgLibSize = 25000
stdLibSize = 5000
outcome = simulateCountData(subjectLoadings, featureLoadings, timeLoadings, numSubjectsPerGroup, numFeaturesPerGroup,
relativeNoise, avgLibSize, stdLibSize)
# Construct additional metadata (especially useful in unbalanced cases)
subjectMetadata = c()
for(i in 1:numTimepoints){
for(j in 1:length(numSubjectsPerGroup)){
subjectMetadata = c(subjectMetadata, rep(LETTERS[j], numSubjectsPerGroup[j]))
}
}
subjectMetadata = cbind(1:sum(numSubjectsPerGroup), subjectMetadata)
featureMetadata = c()
for(i in 1:length(numFeaturesPerGroup)){
featureMetadata = c(featureMetadata, rep(LETTERS[i], numFeaturesPerGroup[i]))
}
featureMetadata = cbind(1:sum(numFeaturesPerGroup), featureMetadata)
# Save data
write.table(subjectMetadata, "./subjectMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureMetadata, "./featureMetadata.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(subjectLoadings, "./subjectLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(featureLoadings, "./featureLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(timeLoadings, "./timeLoadings.csv", sep=",", row.names=FALSE, col.names=FALSE)
write.table(outcome[[2]], "./simData.csv", sep=",", row.names=FALSE, col.names=TRUE)
